# Подсчет токенов - День 7

## Реализованный функционал

### 1. Backend изменения

#### Модели данных (Models.kt)
- Добавлены `AnthropicUsage` и `DeepSeekUsage` для получения информации об использовании токенов из API
- Добавлен `TokenUsageInfo` - универсальная модель для хранения информации о токенах

#### База данных (DatabaseModels.kt)
- Создана таблица `TokenUsage` для хранения статистики использования токенов:
  - `messageId` - ссылка на сообщение
  - `chatId` - ссылка на чат
  - `userId` - ссылка на пользователя
  - `provider` - провайдер AI (claude/deepseek)
  - `model` - используемая модель
  - `promptTokens` - количество токенов в запросе
  - `completionTokens` - количество токенов в ответе
  - `totalTokens` - общее количество токенов

#### AIService (AIService.kt)
- Создан data class `AIResult` для возврата контента и информации о токенах
- Обновлены методы `sendClaudeMessage` и `sendDeepSeekMessage` для извлечения usage из API ответов
- Все вызовы `sendMessage` теперь возвращают `AIResult` с информацией о токенах

#### API Endpoints (ChatRoutes.kt)
- Обновлен endpoint `POST /api/chats/{chatId}/messages` - сохраняет информацию о токенах в БД
- Добавлен endpoint `GET /api/chats/tokens/stats` - общая статистика по пользователю
- Добавлен endpoint `GET /api/chats/{chatId}/tokens` - статистика по конкретному чату

### 2. Frontend

Создана страница **tokens.html** для демонстрации работы с токенами:

#### Функции страницы:
1. **Отображение статистики** - показывает общее использование токенов и разбивку по провайдерам
2. **Тестирование разных размеров запросов:**
   - Короткий запрос (~10 токенов)
   - Средний запрос (~100 токенов)
   - Длинный запрос (~500 токенов)
   - Превышение лимита (с ограничением maxTokens)

#### Для каждого теста показывается:
- Исходный запрос
- Ответ модели
- Подробная статистика токенов (promptTokens, completionTokens, totalTokens, model, provider)

## Как использовать

### Доступ к странице токенов
```
https://defendend.dev/tokens.html
```

### API примеры

#### Получить общую статистику
```bash
curl -X GET "https://defendend.dev/api/chats/tokens/stats" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

Ответ:
```json
{
  "userId": 1,
  "byProvider": [
    {
      "provider": "deepseek",
      "promptTokens": 1234,
      "completionTokens": 5678,
      "totalTokens": 6912
    }
  ],
  "total": {
    "promptTokens": 1234,
    "completionTokens": 5678,
    "totalTokens": 6912
  }
}
```

#### Получить статистику по чату
```bash
curl -X GET "https://defendend.dev/api/chats/123/tokens" \
  -H "Authorization: Bearer YOUR_JWT_TOKEN"
```

Ответ:
```json
[
  {
    "id": 1,
    "provider": "deepseek",
    "model": "deepseek-chat",
    "promptTokens": 45,
    "completionTokens": 123,
    "totalTokens": 168,
    "timestamp": "2025-01-13T..."
  }
]
```

## Примеры тестирования

### 1. Короткий запрос
- **Запрос:** "Привет!"
- **Ожидаемые токены:** ~10 для запроса
- **Результат:** Модель отвечает кратко, используя минимум токенов

### 2. Средний запрос
- **Запрос:** "Расскажи подробно о том, что такое искусственный интеллект..."
- **Ожидаемые токены:** ~100 для запроса
- **Результат:** Модель дает развернутый ответ, используя больше токенов

### 3. Длинный запрос
- **Запрос:** Подробное описание с несколькими вопросами
- **Ожидаемые токены:** ~500 для запроса
- **Результат:** Демонстрирует линейное увеличение токенов с размером запроса

### 4. Превышение лимита
- **Запрос:** "Напиши подробную статью о квантовых компьютерах..."
- **maxTokens:** 50
- **Результат:** Ответ обрезается на 50 токенах, демонстрируя работу лимита

## Обработка превышения лимита

Система корректно обрабатывает превышение лимита токенов:
- DeepSeek API автоматически обрезает ответ до указанного в `maxTokens`
- Claude API также поддерживает `maxTokens` параметр
- Информация об использовании токенов сохраняется даже для обрезанных ответов

## Технические детали

### Как работает подсчет токенов

1. **Отправка запроса** - При вызове AI API отправляется список сообщений
2. **Получение ответа** - API возвращает:
   - Контент ответа
   - Usage информацию (input_tokens, output_tokens)
3. **Сохранение в БД** - Токены записываются в таблицу `token_usage`
4. **Отображение статистики** - Frontend получает данные через API endpoints

### Модели токенов

**Claude API:**
```json
{
  "usage": {
    "input_tokens": 10,
    "output_tokens": 25
  }
}
```

**DeepSeek API:**
```json
{
  "usage": {
    "prompt_tokens": 10,
    "completion_tokens": 25,
    "total_tokens": 35
  }
}
```

### Архитектура

```
User Request → ChatRoutes → AIService → AI API
                  ↓              ↓
            TokenUsage DB  ← AIResult (content + usage)
```

## Файлы изменений

1. `/src/commonMain/kotlin/app/Models.kt` - добавлены usage модели
2. `/src/jvmMain/kotlin/app/models/DatabaseModels.kt` - таблица и DTO для токенов
3. `/src/jvmMain/kotlin/app/database/DatabaseFactory.kt` - создание таблицы
4. `/src/jvmMain/kotlin/app/services/AIService.kt` - возврат информации о токенах
5. `/src/jvmMain/kotlin/app/routes/ChatRoutes.kt` - сохранение и API endpoints
6. `/src/jsMain/resources/tokens.html` - страница демонстрации

## Выводы

Реализация подсчета токенов позволяет:
- **Мониторить использование** - отслеживать расход токенов по пользователям и провайдерам
- **Оптимизировать запросы** - понимать, как размер запроса влияет на стоимость
- **Контролировать лимиты** - устанавливать ограничения на размер ответов
- **Анализировать поведение** - изучать, как модели обрабатывают разные типы запросов

Система корректно работает как с короткими (10 токенов), так и с длинными запросами (500+ токенов), а также правильно обрабатывает превышение установленных лимитов.
